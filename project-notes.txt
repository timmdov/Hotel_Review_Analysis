ML_SentimentAnalysis/
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/                            # Raw scraped datasets
â”‚   â”œâ”€â”€ interim/                        # Cleaned but not yet annotated
â”‚   â”œâ”€â”€ processed/                      # Final labeled datasets
â”‚   â””â”€â”€ results/                        # Evaluation logs, plots, predictions
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                       # Jupyter notebooks for experimentation
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_model_comparison.ipynb
â”‚   â”œâ”€â”€ 03_topic_modeling.ipynb
â”‚   â””â”€â”€ 04_multilingual_demo.ipynb
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚
â”‚   â”œâ”€â”€ ğŸ“ preprocessing/               # All text preprocessing logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cleaner.py                 # Normalize, remove emojis, punctuation
â”‚   â”‚   â”œâ”€â”€ stopwords.py              # Custom Turkish/English stopwords
â”‚   â”‚   â”œâ”€â”€ lemmatizer.py             # spaCy/Zemberek lemmatization
â”‚   â”‚   â””â”€â”€ language_detect.py        # langdetect or fastText lang ID
â”‚
â”‚   â”œâ”€â”€ ğŸ“ annotation/                 # Labeling logic
â”‚   â”‚   â”œâ”€â”€ vader_wrapper.py          # VADER sentiment for English
â”‚   â”‚   â”œâ”€â”€ rule_based_tr.py          # Rule-based sentiment for Turkish
â”‚   â”‚   â””â”€â”€ bert_predict.py           # BERT-based sentiment
â”‚
â”‚   â”œâ”€â”€ ğŸ“ vectorization/
â”‚   â”‚   â”œâ”€â”€ count_vectorizer.py
â”‚   â”‚   â”œâ”€â”€ tfidf_vectorizer.py
â”‚   â”‚   â””â”€â”€ bert_embedder.py         # BERT embeddings if needed
â”‚
â”‚   â”œâ”€â”€ ğŸ“ models/
â”‚   â”‚   â”œâ”€â”€ train_logreg.py
â”‚   â”‚   â”œâ”€â”€ train_svm.py
â”‚   â”‚   â”œâ”€â”€ train_bert.py
â”‚   â”‚   â””â”€â”€ evaluate.py              # Metrics, confusion matrix, reports
â”‚
â”‚   â”œâ”€â”€ ğŸ“ multilingual/
â”‚   â”‚   â”œâ”€â”€ translate.py             # Google Translate / Argos API
â”‚   â”‚   â””â”€â”€ multilingual_router.py   # Route reviews to correct model
â”‚
â”‚   â”œâ”€â”€ ğŸ“ utils/
â”‚   â”‚   â”œâ”€â”€ io.py                    # Load/save files
â”‚   â”‚   â””â”€â”€ visualization.py        # Plotting confusion matrix, class dist
â”‚
â”‚   â”œâ”€â”€ ğŸ“ pipeline/                 # End-to-end pipeline runners
â”‚   â”‚   â”œâ”€â”€ model_logreg.py
â”‚   â”‚   â”œâ”€â”€ model_berturk.py
â”‚   â”‚   â”œâ”€â”€ model_multilang.py
â”‚   â”‚   â””â”€â”€ evaluate_all.py         # Compare all models
â”‚
â”œâ”€â”€ ğŸ“ tests/                         # Unit tests for modules
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_pipeline.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore


# ğŸ“ ML_SentimentAnalysis - Project Structure Notes

This project is designed for multilingual sentiment analysis of hotel reviews.
It supports both classical machine learning and transformer-based models,
as well as preprocessing, translation, topic modeling, and evaluation.

--------------------------------------------------------
ğŸ“‚ data/
- raw/           â†’ Raw scraped reviews (untouched CSVs)
- interim/       â†’ Cleaned but not fully labeled datasets
- processed/     â†’ Final datasets: preprocessed, labeled, ready for modeling
- results/       â†’ Stores output logs, model metrics, saved models, confusion matrices

NOTE: All data subdirectories are tracked in .gitignore EXCEPT structure (via .gitkeep)

--------------------------------------------------------
ğŸ“‚ notebooks/
- eda.ipynb             â†’ Initial data exploration and visualization
- topic_modeling.ipynb  â†’ LDA or BERTopic applied to clustered review themes
- multilingual_demo.ipynb â†’ Language detection, translation, multilingual routing demo

TIP: Use these to prototype ideas before converting to pipeline scripts

--------------------------------------------------------
ğŸ“‚ src/
Contains the core modular Python packages of the project.

ğŸ“ preprocessing/
- cleaner.py        â†’ Normalize, remove emojis/punctuation
- stopwords.py      â†’ Load custom stopword lists (e.g., Turkish)
- lemmatizer.py     â†’ spaCy or Zemberek lemmatization
- language_detect.py â†’ Language detection using langdetect or fastText

ğŸ“ annotation/
- vader_wrapper.py  â†’ English sentiment with VADER
- rule_based_tr.py  â†’ Simple Turkish sentiment rules (optional)
- bert_predict.py   â†’ Use BERT models like BERTurk or XLM-R for sentiment classification

ğŸ“ vectorization/
- count_vectorizer.py â†’ Scikit-learn CountVectorizer logic
- tfidf_vectorizer.py â†’ TF-IDF vectorizer with filtering and n-grams
- bert_embedder.py    â†’ Convert text to BERT embeddings if needed

ğŸ“ models/
- train_logreg.py   â†’ Logistic Regression training logic
- train_svm.py      â†’ SVM model (if used)
- train_bert.py     â†’ HuggingFace BERT model training
- evaluate.py       â†’ Outputs metrics: Accuracy, F1, confusion matrix, etc.

ğŸ“ multilingual/
- translate.py      â†’ Translate text via API (Google, Argos)
- multilingual_router.py â†’ Choose model per language (mBERT, BERTurk, etc.)

ğŸ“ utils/
- io.py             â†’ Read/write CSV, pickle models
- visualization.py  â†’ Confusion matrix, bar charts, word clouds
- logger.py         â†’ Project-wide logger for consistent output

--------------------------------------------------------
ğŸ“‚ pipeline/
This is where we run complete model pipelines.

- model_logreg.py     â†’ CountVectorizer + Logistic Regression
- model_berturk.py    â†’ BERTurk for Turkish sentiment
- model_multilang.py  â†’ Mixed-language handling (language detect â†’ route)
- evaluate_all.py     â†’ Compare all models on a common dataset

Run any of these from command line or PyCharm:
$ python src/pipeline/model_berturk.py

--------------------------------------------------------
ğŸ“‚ tests/
Unit tests for ensuring modules work independently.
Use `pytest` or `unittest` to validate logic as the project grows.

--------------------------------------------------------
ğŸ“ Other Files
- requirements.txt â†’ All required Python packages (export via pip freeze)
- README.md        â†’ General project overview (for GitHub)
- .gitignore       â†’ Prevents data/results/models from being tracked in Git
- project_structure_notes.txt â† THIS FILE

--------------------------------------------------------

âœ… RECOMMENDED WORKFLOW
1. Place raw CSV in `data/raw/`
2. Preprocess and save to `data/processed/`
3. Choose and run a pipeline in `src/pipeline/`
4. Save metrics to `data/results/` + logs via `logger.py`
5. Use notebooks for further exploration or tuning

--------------------------------------------------------
